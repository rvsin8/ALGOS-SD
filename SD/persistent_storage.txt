# Persistent Storage

This is one topic that needs little introduction in today’s day and age. Today, where vast amounts of data are generated, collected, and processed every second, databases and persistent storage systems play a pivotal role in storing, organizing, managing, and retrieving information efficiently. From e-commerce platforms and social media networks to banking systems and healthcare applications, databases serve as the backbone of data management, ensuring data integrity, availability, and accessibility.

Databases serve as centralized repositories for storing data. Data could be structured, semi-structured or unstructured data, and database systems allow applications to access and manipulate information efficiently. By providing a structured framework for data storage and retrieval, databases enable organizations to organize, analyze, and derive insights from their data assets.

**Evolution over Time**

In today's world, where data is generated at an unprecedented rate, databases play a crucial role in enabling businesses to harness the power of data-driven decision-making. Whether it's tracking customer transactions, analyzing user behavior, or managing inventory levels, databases provide the foundation for businesses to optimize operations, drive innovation, and deliver personalized experiences to users. However, if we rewind back a few decades and analyze the evolution of databases over time, we’ll be amazed. Not only to see how technology has advanced but also how the exponential growth of data and changing business requirements have contributed to the evolution of storage systems over time. Here are some of the ways databases have evolved:

1. **Basic Data Storage to Advanced Query Capabilities:** Initially, databases focused on basic data storage and limited query patterns. With technology advancing, query capabilities expanded, allowing for more complex data analysis and reporting.
2. **Diverse Data Types and Use Cases:** As data volumes and variety increased, databases evolved to support a broader range of data types and specialized use cases. This led to the emergence of specialized database systems such as document databases, key-value stores, column-family stores, and graph databases, catering to specific data management requirements and use cases.
3. **Scalability Challenges and Cloud Adoption:** The rise of big data and cloud computing posed scalability challenges for traditional databases, leading to the adoption of cloud-native database solutions. Cloud databases offer scalability, flexibility, and cost-effectiveness for managing data at scale.
4. **Integration with Emerging Technologies:** Database systems are increasingly integrating with emerging technologies such as AI, ML, blockchain, and IoT to enhance data analytics, automation, and decision-making capabilities, enabling organizations to leverage data-driven insights and innovations.

**Online Databases and Offline Databases**

**Online Databases**

Online databases are designed to be continuously available and accessible for query and manipulation in real-time. They serve as the backend storage systems for various online applications, enabling users to interact with data dynamically.

**Examples are MySQL, PostgresSQL, MongoDB**. Here are some key characteristics and considerations of online databases:

1. **Real-Time Access**: Online databases support real-time access to data, allowing users and applications to retrieve, update, and manipulate data instantly. This real-time access is essential for applications that require immediate responses to user queries and interactions, such as e-commerce platforms, social media networks, and banking systems.
    1. Real-time access ensures data is **instantly available for reading or writing**. This is essential for applications where users expect immediate feedback.
    2. **Example:**
        - Imagine an **e-commerce site** where users add items to a cart. Real-time access ensures the inventory updates as soon as someone places an order.
        - Without real-time access, users might see outdated inventory, leading to overbooking or disappointment.
    3. Databases achieve this through **caching** and **connection pooling** to keep query response times low.
        - **How it works:** If a user queries the price of a product, the database serves it directly from cache instead of re-processing the query every time.
        - **Locking:** Only one user can modify a record at a time, e.g., editing a movie title locks the title field.
        - **Transactions:** Ensure all operations in a process succeed together. Example: Transferring money involves two steps: deducting from one account and adding to another. If one step fails, both are rolled back.
2. **Concurrent Access**: Online databases are designed to handle concurrent access from multiple users or applications simultaneously. They employ concurrency control mechanisms, such as locking, transactions, and isolation levels, to ensure data integrity and consistency in multi-user environments.
    1. Multiple users or applications can interact with the database at the same time without conflicts.
    2. **Example:**
        - Think of **Netflix**, where millions of users stream videos and add shows to watchlists simultaneously.
        - If two users try to modify the same show entry (e.g., add reviews), the database ensures the changes don’t corrupt each other.
3. **Optimized for Performance**: Online databases are optimized for performance to deliver low-latency responses to user queries and transactions. They employ indexing, query optimization, caching, and other performance-enhancing techniques to minimize response times and improve overall system efficiency.
    1. Online databases prioritize speed for both reading and writing operations, essential for seamless user experiences.
    2. **Example:**
        - **Instagram** posts appear instantly after you share them. The database must handle both the upload (write) and visibility (read) efficiently.
        - **Indexing:** Posts are stored in a way that finding "posts with #travel" is super-fast—like a search index in a book.
            - **Indexing:**
                - Speeds up searches, e.g., searching for all posts by a user. Without it, the database scans every post.
    3. **Query Optimization:**
        - A poorly written query (e.g., `SELECT * FROM posts`) fetches everything and slows the database. Query optimizers rewrite such queries for efficiency.
    4. **Replication:**
        - Duplicates data across servers so reads can be handled by replicas, while the main server handles writes.
        

**Question:** Why would a banking app fail without real-time access to data like account balances?

**Answer:** Without real-time access, users might see outdated balances, leading to overdrafts or fraudulent transactions as the system wouldn't reflect recent changes instantly.

**Question:** If two users try to book the last Airbnb at the same time, what prevents overbooking?

**Answer: Transactions** and **locking** ensure that only one user’s booking request is processed at a time, preventing the same property from being reserved twice.

**Question:** Why might indexing slow down write-heavy applications like real-time messaging?

**Answer:** Indexing requires updates every time data is inserted or modified, adding overhead to write operations, which can slow down systems with frequent writes like messaging apps.

**Offline Databases**

Offline databases, also known as batch databases, are used for storing and processing data in bulk at scheduled intervals, typically during periods of low activity or downtime. While offline databases are not accessible for real-time interactions, they play a crucial role in performing batch processing, data analysis, and reporting tasks.

**Examples are Apache Hadoop** (with its component called Apache Hive)

1. **Batch Processing:** Offline databases are used for batch processing tasks where data is processed in bulk at scheduled intervals or during predefined batch windows. This may involve tasks such as data extraction, transformation, loading (ETL), analytics, and reporting.
    1. Offline databases are ideal for tasks where data processing doesn’t need to happen instantly. For instance, calculating payroll, consolidating sales data, or updating customer records can be queued and executed in one go during off-hours. This allows systems to efficiently handle large datasets without impacting online services.
2. **Scheduled Updates:** Data in offline databases is updated periodically based on predefined schedules or triggers. These updates may involve data imports, exports, transformations, and aggregations performed offline without real-time user interactions.
    1. Offline databases update data periodically instead of in real-time. This is useful when immediate data consistency isn’t critical. For example, a retail chain might synchronize inventory levels from individual stores to a central system every night, avoiding constant synchronization overhead.
3. **Reduced Operational Overhead:** Since offline databases do not require continuous availability and real-time responsiveness, they typically have lower operational overhead compared to online databases. This allows organizations to optimize resource utilization and reduce infrastructure costs for offline processing tasks.
    1. Since offline databases don’t need to be always accessible, they require less expensive infrastructure. There’s no need for high-availability setups or optimized query performance during downtime. This translates into lower costs for storage and processing.
4. **Resource Efficiency:** Offline databases can leverage batch processing techniques to optimize resource utilization and achieve better performance efficiency for data-intensive tasks. They can process large volumes of data more efficiently by batching similar operations and maximizing parallelism.
    1. Offline databases excel at resource utilization by handling large datasets in bulk. By grouping similar operations—like aggregations or data cleaning—they minimize repeated tasks and make better use of available computing power, often leveraging parallel processing.
5. **Data Analysis and Reporting:** Offline databases are often used for data analysis, reporting, and business intelligence (BI) purposes, where historical data is analyzed to derive insights, trends, and patterns over time. They enable organizations to perform complex analytics and generate reports based on aggregated data from multiple sources.
    1. Offline databases are perfect for tasks like business intelligence and historical trend analysis. These computations can be complex and time-consuming but don’t need to run in real time. An example would be generating quarterly sales reports or identifying trends from years of customer data.

**Question: It seems like online databases give us the flexibility of real time updates and queries. Why use offline databases when you can just put in all your data in online databases?**

The short answer is that *there is no free lunch*.

1. **Cost**. Since offline databases are in some sense “read only” (don't allow real time updates) and not real time, they can be a lot more cost effective than real time database systems. The reason being that real time database systems consume a lot more hardware and software resources with the real time features they provide.
2. **Query Patterns and performance** Some data processing tasks are inherently batch-oriented and do not require real-time processing. For example, large-scale data analysis, reporting, and data transformation tasks can be more efficiently performed in batch mode, especially when dealing with large volumes of data. Also, by aggregating and processing data in batches, organizations can optimize performance and reduce the overhead associated with handling individual transactions or real-time updates. Batch processing allows for parallelism, optimization, and resource allocation strategies that can improve overall system efficiency.

**Additional Reading**

[](https://www.notion.so/150915a5a537804f9a38cd5e2d1a281d?pvs=21)

**Standalone Databases and Distributed Databases**

As their name suggests, a standalone database resides on a single server or machine and is managed as a single unit. It consists of a single instance of the database management system (DBMS) running on a single server, handling all data storage and processing tasks locally. On the other hand, a distributed database spans multiple servers or nodes, with each node containing a subset of the data. Data is distributed across multiple nodes, and the database management system coordinates data access and processing across the distributed environment.

To better understand the difference between these two types of databases, let’s start by looking at two real-life examples of data models.

**Advertiser and Ads Data**

Let's consider a database that lets advertisers manage their campaigns. There are 3 entities in the picture, advertiser, campaign, and ad. An advertiser entity can have multiple campaigns running. Each campaign entity can have multiple ads running.

**Side Note**

Note how the relationship between a) Campaigns and Advertisers and b) Ads and Campaigns is maintained. Since it is a many-to-one relationship, the parent ID resides in the child table.

This simple database system allows advertisers to create, update and view their campaigns and ads.

**User Metadata**

Now consider a totally different system that simply shows information about a User and allows the User to edit these free text fields. Users can also add miscellaneous free data to their entity object. This is what the model looks like:

Note that this system simply allows Users to view their Data given an ID and allows the User to update their data given their ID.

**Comparing the Models**

With these two fairly different data models in mind, let's analyze a few things.

**Schema, data model and flexibility**

Note that the first example has data in structured tables with rows and columns, following a predefined schema. Data relationships are established through foreign key constraints. The model is also a lot more strict and less flexible, any attribute that needs to be added would mean that you would need to change the database schema.

On the other hand, although the second example has *some* structure, it is a lot more “schema less” meaning that user metadata could have any arbitrary information, different users could have different keys and keys could be added and removed arbitrarily.

**Query patterns**

The first system would need to address a lot more complex queries that involve joins. For example, “give me all ads of this advertiser” or “give me all ads of this campaign ID”. This would mean that we would have to join data from multiple tables using the foreign key constraints.

For the second example, the queries are a lot more **“point queries”**. Which means the only real query constraint is the ID. All reads and updates are done to this single object using the ID without using any joins.

**Additional Reading on Data Models**

[Relational Model vs. Document model:- Chapter 2. Data models and Query languages, Designing Data Intensive Applications.](https://www.notion.so/Relational-Model-vs-Document-model-Chapter-2-Data-models-and-Query-languages-Designing-Data-Int-150915a5a53780689d12e49fa53e6665?pvs=21)

**Defining Relational and Non-Relational Databases**

The two different use cases explain how two different types of database systems work and are used. With these two examples in mind, let’s jump in to see how relational databases and non-relational databases work.

**Relational Databases**

Relational databases organize data into structured tables with rows and columns, adhering to a predefined schema. Tables represent entities or relationships in the data model, with each row representing a record and each column representing a specific attribute or field. Every table complies with a predefined schema and if any columns need to be added then the schema change needs to be applied beforehand on the entire database table.

Data is stored in **tables** with strict **rows** (records) and **columns** (attributes), adhering to a **schema** (predefined structure).

Relational databases enforce data integrity constraints, such as primary key, foreign key, unique key, and check constraints, to maintain data consistency.

Integrity enforces rules like **primary keys**, **foreign keys**, and **unique constraints** to ensure data consistency.

Usually, relational databases scale less than non-relational databases, and are less performant (think about a) Transactional Support, b) all the integrity checks that need to be made after every transaction). At that cost, they provide high data integrity and high reliability and better support for joins.

Use SQL (Structured Query Language) for **complex joins**, aggregations, and relationships between data.

For querying, relational databases usually use SQL style query languages.  We will look at Relational Databases with more depth in the next chapter.

**Transactional Support**: Follows **ACID properties** (*Atomicity, Consistency, Isolation, Durability*).

**Joins**: Excellent for handling **relationships** between entities (e.g., *many-to-one or one-to-one*).

**Reliability**: Ideal for scenarios requiring **strict consistency** (e.g., *banking or e-commerce transactions*).

**Limitations**:

- Less scalable for massive datasets.
- Schema changes can be challenging.

**Examples**: MySQL, PostgreSQL.

**Non-Relational Databases (e.g. Key-Value Stores, Document Databases)**

These databases don't use the tables, fields, and columns structured data concept from relational databases. NoSQL databases were developed to suit the second example. When the data is such that it doesn't need to be tied down by strict schemas, and the flexibility of adding keys is wanted, it is an attractive choice. Also, when there are no relations between different entities and queries are frequently “point” queries, it could be a good option to go with non-relational databases.

Schema-less, flexible storage models (e.g., key-value, document, column-family).

Non-relational databases generally scale more easily than relational databases and thus can achieve higher throughput. They do well with large amounts of data and are more performant (because of no integrity or schema checks). Of course, at that cost, they often don't provide transactional support (we will speak about this later) and are less performant for queries with joins.

Easily scales horizontally for large datasets and high throughput.

Handles unstructured or semi-structured data; easy to add fields.

Faster for simple operations (e.g., point lookups), no schema or integrity constraints.

Like mentioned above, non-relational databases also don't do so well with relationships (one to one and many to one). If your system has entities that are usually fully loaded at once and somewhat isolated (not connected with other entities), then this is a good option to go with.

Not ideal for one-to-one or many-to-one relationships.

Often lacks full ACID compliance.

Struggles with joins or multi-entity.

**Examples**: MongoDB (**documents**), Redis (**key-value**), Cassandra (**wide-column**).

**Best For**: Isolated entities, real-time analytics, caching, large-scale applications.

**Key Insight**: Use when data relationships are minimal and scalability is critical.

**Relational Database**

**Strict Schemas/Data Model**

As mentioned before, relational databases ensure that each database table has a predefined schema. Every column has a data type. Ids are usually primary keys and relationships are maintained with the help of foreign keys. Whenever new attributes (columns) need to be added in the database, the schema has to be changed beforehand and those schema changes need to be applied to the database before that new column can be used.  Based on the requirements of your system, here are some of the pros and cons of having a strict schema.

Each table has a fixed structure, with **columns having specific data types**.

Tables are linked using **primary keys** and **foreign keys**, enforcing **referential integrity**.

**Adding new columns requires updating the schema** across the database.

**Pros**

- **Clean data, reduced possibility for corruption**. Having data types for each column means that the database will make sure that, in general, garbage data will not enter the db. The schema ensures data integrity and consistency, preventing invalid or inconsistent data from being stored in the database.
    - Schema enforces data validation.
    - Prevents garbage data (e.g., storing a string in a numeric column).
- **Data organization and clarity**. A structured database table is a lot easier to understand and interact with in code.
    - Structured tables make relationships and data easier to understand.
    - Predictable format simplifies coding and querying.
- **Data Integrity.** Having constraints for every column enable having data integrity. For example, Not null columns will make sure there is no null data entered. Foreign key constraints also make sure that the values entered as foreign keys are valid rows in the foreign table. (This is called **Referential Integrity**).
    - **Constraints**:
        - `NOT NULL`: Ensures columns always have a value.
        - **Foreign Keys**: Guarantees linked data exists (e.g., valid user IDs in a transactions table).
    - Maintains consistency between related tables.
- **Query Optimization and performance**. Since the database knows so much about the table, it can optimize query execution plans and generate efficient queries internally, reducing the time and resources required to retrieve and manipulate data.
    
    For example, it can use indexed columns to drastically eliminate rows and cut down the search space.
    
    - **Indexes**:
        - Accelerate searches by creating a "shortcut" for queries.
        - Great for columns that are frequently searched or used in joins.
    - **Query Execution Plans**:
        - Database optimizes the retrieval process using knowledge of schema, constraints, and indexes.
        - Results in faster data access and efficient resource use.
        

In an **e-commerce application**:

- **Users Table**: Schema ensures user IDs are unique (`Primary Key`).
- **Orders Table**: References user IDs (`Foreign Key`) to enforce valid relationships.
- Queries like "fetch all orders for a user" are highly efficient due to structured data and indexed columns.

**Cons**

- **Lack of flexibility.** Having a strict schema means that every new addition of columns needs a schema change applied to the database. This makes it hard for cases where attributes keep changing frequently.
    - **Schema-bound**: Adding new columns requires schema updates.
    - In dynamic systems (e.g., social media with ever-changing metadata), schema rigidity can hinder adaptability.
- **Performance loss on schema updates.** When schema changes alter the table, it could mean downtime since the table will be “locked”.
    - Schema changes (e.g., adding/removing columns) may **lock tables**, preventing reads/writes during updates.
    - This can lead to **downtime** in high-traffic systems.
- **Query Performance.** It's understandable that the database is doing a lot of work and checks while writing data (constraints, datatype checks, referential integrity checks, etc.), which means in general queries, specially write queries in relational DBs are much slower than in non-relational DBs.
    - Relational databases perform extensive checks during writes:
        - **Constraints validation**: Ensures data adheres to rules (`NOT NULL`, `UNIQUE`, etc.).
        - **Data type enforcement**: Prevents invalid data entries.
        - **Referential integrity checks**: Confirms foreign keys reference valid rows.

These operations ensure reliability but increase write latency compared to non-relational databases.

**Transactions/ACID**

Lets see an example of a banking system. Users A and B have bank accounts and user A transfers some money into account B. At a high level, here are all the database operations that happen behind the scenes:

1. Check if A has the balance
2. Deduct money from A’s balance
3. Add money to B’s balance
4. Check if B’s account is correct

Now imagine that after step 2, the database goes down for some reason. It would be detrimental to have the balance deducted from A’s account and not added to B, correct? This is where the concept of a transaction comes into play.

In the context of a relational database, a transaction refers to a logical unit of work that consists of one or more database operations (such as inserts, updates, or deletes) that are executed as a ***single, indivisible*** unit. This means that either **all the operations happen** or **they all don’t**. The concept of a transaction is fundamental to ensuring data integrity, consistency, and reliability in relational databases.

Transactional support is one of the key aspects of relational databases and something that we must consider strongly when selecting the right kind of database for our system. If there are cases where we want all or nothing, relational databases offer a lot more native support for transactions than a non-relational databases

The key aspects of a transaction are **atomicity, consistency, durability, and isolation**. This is where the acronym **ACID** comes from. Let's look at each of them briefly.

1. **Atomicity**
    1. Atomicity ensures that all operations within a transaction are executed as a single, indivisible unit. Either all operations in the transaction are **completed successfully, or none of them are**.
    2. If any operation within the transaction fails or encounters an error, the entire transaction is rolled back, and the database returns to its previous state (i.e., all changes made by the transaction are undone).
2. **Consistency**
    1. Consistency guarantees that the database remains in a valid and consistent state before and after the execution of a transaction.
    2. Transactions must adhere to all integrity constraints, such as primary key constraints, foreign key constraints, and unique constraints, to **ensure the integrity of the data**.
3. **Isolation**
    1. Isolation ensures that the changes made by one transaction are isolated from the changes made by other concurrent transactions.
    2. Concurrent transactions execute as if they were isolated from each other, **preventing interference and maintaining data integrity**.
    3. Isolation levels, such as Read Uncommitted, Read Committed, Repeatable Read, and Serializable, define the degree of isolation between concurrent transactions.
4. **Durability**
    1. Durability guarantees that the changes made by a committed transaction persist even in the event of a system failure or crash.
    2. Once a transaction is committed, its changes are written to durable storage (such as disk) and remain intact, even if the system crashes or loses power.

**Data Modeling with Relational Database**

In the previous unit, the Advertiser and Ads data system was a good example of an object model. Lets look at another data model known as the “Graph Data Model” and how we can use relational databases to implement this data model to represent nodes and edges

**Graph Data Model**

Consider a social network where users have other friends, followers and posts.

- Users can author Posts. A post can have only one author.
- Users can be friends with other users. This is a bidirectional edge, which means if A is a friend of B, B is a friend of A too
- Users can follow other users. This is a unidirectional edge, A following B does not mean that B follows A too.

**Modeling Graphs in Relational DBs**

**How would we model this graph in a relational DB?**

First, every node will have its own table. So here, we would have 2 node tables, User and Post.

Next, the User <-> Post mapping is a one to many relationship and therefore the post table can have a ***foreign key*** for its author pointing to User ID. Following the above two points here is what the User table and Post Table would look like:

The graph data model is a way to represent relationships (edges) and entities (nodes). Here's how this model is applied to a relational database using a **social network** example:

**Nodes as Tables**

**Users**: Each user is a node, so we use a `User` table.

- **Columns**:
    - `ID` (Primary Key)
    - `First Name`, `Last Name`, `Country`, `Currency`

**Example**:

```sql
sql
Copy code
| ID  | First Name | Last Name | Country  | Currency |
|-----|------------|-----------|----------|----------|
| 1   | Alice      | Smith     | USA      | USD      |
| 2   | Bob        | Johnson   | Canada   | CAD      |

```

**Posts**: Each post is another node, linked to a user by a foreign key `Author_id`.

- **Columns**:
    - `ID` (Primary Key)
    - `Author_id` (Foreign Key referencing `User.ID`)
    - `Post Text`

**Example**:

```lua
lua
Copy code
| ID  | Author_id | Post Text           |
|-----|-----------|---------------------|
| 1   | 1         | Hello, world!       |
| 2   | 2         | Exploring Canada!   |

```

| Column 1 | Column 2 | Column 3 | Column 4 | Column 5 |
| --- | --- | --- | --- | --- |
| ID | First Name | Last Name | Country | Currency |

| Column 1 | Column 2 | Column 3 |
| --- | --- | --- |
| ID | Author_id (Foreign Key to ID column of the User table) | Post Text |

**Edges as Tables**

**User Relationships**:

- Represent **many-to-many relationships** (e.g., friendships and follows) in a separate **Edge Table**.
- **Columns**:
    - `From_ID` (Foreign Key referencing `User.ID`)
    - `To_ID` (Foreign Key referencing `User.ID`)
    - `Edge Type` (e.g., `FRIEND`, `FOLLOWS`)

**Example**:

```vbnet
vbnet
Copy code
| From_ID | To_ID | Edge Type |
|---------|-------|-----------|
| 1       | 2     | FRIEND    |
| 2       | 1     | FRIEND    |
| 1       | 3     | FOLLOWS   |

```

The friends and following edges represent many to many relationships. One way of representing many to many relationships is to have a ***separate edge table*** to represent those edges. The edge table can have one column as the **from_node**, the other one as **to_node** and one column that mentions the edge type. For example with respect to the diagram above we could have:

| Column 1 | Column 2 | Column 3 |
| --- | --- | --- |
| From_ID | To_ID | Edge Type |
| USER ID 1 | USER ID 2 | FRIEND |
| USER ID 2 | USER ID 1 | FRIEND |
| USER ID 1 | USER ID 3 | FOLLOWS |

There are some discussions on whether to have a separate table for each edge type or whether to keep them in the same table with a column that denotes the edge type. The answer depends on a lot of things such as how much we expect the data to grow and whether one table might become too big.

- One general consensus is that if we expect to introduce new edge types all the time, have a separate table for each might become a big overhead in terms of schema changes and so on.
- If each edge table has a lot of metadata that itself might need structure, then maybe it's okay to have one table per edge type.

**Design Considerations**

1. **One Table for All Edge Types**:
    
    Use a single table for relationships (e.g., `Edge Type` column distinguishes between `FRIEND` or `FOLLOWS`).
    
    **Pros**: Easier to manage schema changes when adding new edge types.
    
    **Cons**: A large table can become less performant as data grows.
    
2. **Separate Tables for Each Edge Type**:
    
    Create a different table for each relationship type (e.g., `Friends Table`, `Follows Table`).
    
    **Pros**: Allows better structuring if each relationship type has its own metadata.
    
    **Cons**: Inflexible for frequently changing or new edge types.
    

The purpose of this excerpt is to explain how to model a **Graph Data Model** (nodes and edges) in a **Relational Database** using a **social network** example, with a focus on:

1. **Nodes as Tables**: Represent entities (e.g., Users and Posts) as relational tables with columns for attributes and foreign keys for relationships.
2. **Edges as Tables**: Represent relationships (e.g., friendships and follows) as separate tables to handle many-to-many connections, using columns for source, target, and relationship type.
3. **Design Considerations**
    
    **Single Table for All Edges**: Simplifies schema management but may affect performance with large datasets.
    
    **Separate Tables for Each Edge Type**: Offers better structure for metadata-heavy relationships but is less flexible for frequent schema changes.
    

**Non-Relational Database**

We saw an introduction to non-relational databases in the previous unit. Let’s dig into some more concepts pertaining to these systems in a little more detail.

**Key Concepts and Example**

**Schema-Less/Flexible Data Model**:

**Structure**: Non-relational databases, like key-value stores or document databases, do not follow strict schemas. The "value" is a blob (e.g., JSON), allowing the structure to evolve dynamically.

**Example**: A user metadata system:

```json
json
Copy code
{
  "User_ID_1": {
    "First_name": "Foo",
    "Last_name": "Bar",
    "Location": "SF",
    "Interests": ["Tech", "Music"]
  }
}

```

New fields (like "Interests") can be added without modifying a predefined schema.

**Why Use It?**

- New fields can be added anytime without downtime or schema migrations.
- Perfect for use cases like user profiles where fields change often.

**Advantages**

1. **Flexibility**:
    - Rapidly evolving systems can adjust without requiring schema updates, reducing downtime and accelerating development.
    - Ideal for unstructured or semi-structured data.
    - **Example**: Product catalogs with varying attributes like size, weight, or color.
2. **Performance**:
    - Faster writes since there are no schema validations or foreign key checks.
    - They are optimized for fast insertions.
    - **Example**: Logging systems where speed is critical.
    
    **Not Good For**:
    
    - **Complex relationships** (e.g., joins between tables).
    - **Strong consistency or transaction-heavy systems** (e.g., banking).

**Flexible Data Model/Schema-less**

In general, non-relational databases work like key-value stores. They do not store data in rows and columns like the way relational databases store data. Rather, the value is usually a data blob, meaning it can have a fuzzy structure that changes from time to time. This way, the data is not tied down to a strict schema.

Let's look at an example. Let's assume, we have a database that stores metadata about a user. Metadata could be first name, last name, location, and email.

The system allows users to view their data, edit their data and also new users to add their data.

Now, we can imagine that with a system like this, there will always be an opportunity to include more and more metadata. For example, it's possible that a little later down the line we add date of birth, interests, educational background, professional background, etc.

Now if this system was modeled with a relational database, then every time a new field was added, we would have to change the entire schema of the table and apply the schema to the database before it could be used. This could mean slower development time, database downtime, and if it happens often enough, it could really slow things down (both development-wise and performance-wise). Therefore, in this case, a good choice would be to have a key-value store or a document database whose key would be the ID of the user and value would be a JSON block of all the information.

```
{
  "User_ID_1": {
    "First_name": "Foo",
    "Last_name": "Bar",
    "Location": "SF",
    ...
  },
  ...
}

```

In a schema-less model:

1. **Key** acts like a unique identifier (like a locker number).
2. **Value** is the data stored (like the contents of the locker), often represented as a JSON object or blob, allowing dynamic and varying structures.

Imagine a **relational database** as a vending machine. Each slot in the machine is predefined (rows and columns), e.g., slot "A1" for "Chips". If you want to sell a new product, you'd need to redesign the machine to add a new slot.

Now imagine a **schema-less database** as a storage shelf. You can put any item in any spot without modifying the shelf. Need to store chips today and umbrellas tomorrow? No problem—it’s flexible and quick.

**Relational Database Challenge**: Schema change required—time-consuming and may cause downtime.
**Schema-less Solution**: Simply add new fields to the JSON blob for that user without impacting others.

**Example Scenario:**

- A database tracks user metadata (name, location, etc.).
- Initially: Only basic fields like name, location.
- Later: New fields like date of birth or professional background are added.

**Pros**

- **Flexibility of data model**: We are not bogged down by strict schemas and painful schema changes. Fast evolving systems benefit hugely from this. Evolving systems benefit as developers can add new fields without schema migrations.
    
    Analogy: It’s like using a whiteboard where you can add or erase notes easily, compared to a printed page where changes require reprinting.
    
- **Faster writes:** Non-relational databases perform better in general during writes. Imagine not having to validate the data schema, data types, foreign keys, etc. No schema validation means data gets written quickly.
    
    Analogy: Like skipping security checks at the airport—faster but less regulated.
    

**Cons**

- **Increased possibility of corruption**: Since the data is simply a blob, it's possible for bad data to get in if not handled by the application code correctly. For example, at a DB level, there is no check for what the JSON keys are.
    
    No enforced schema means invalid or inconsistent data may sneak in.
    
    Analogy: Like leaving a shelf unorganized; if someone puts a shoe in a cereal box, you’ll only notice later.
    
- **Less clarity and data organization:** If you look at a relational table, just a glance at the schema can tell you what the data would look like. However, in a non-relational DB, that's very hard to tell because in theory, every JSON blob of different data points could have a different set of keys in them.
    
    Unlike relational schemas, where data relationships are clear, schema-less databases can appear chaotic.
    
- **No support for join queries**: Since the data is unstructured, if your system has queries that need to join multiple non-relational tables, the query performance could be poor. In the above example, let's assume you have another key-value store of locations keyed by ID, like this: Now if the User metadata has a location pointing to this ID (instead of the name string), then for a query like “Give me all users in San Francisco”, you would have to parse through all the users’ information and one by one, match it with the above table to get the result. This would be something a relational database would do much better with joins.
    
    **No optimized joins**: You manually match related data (e.g., user locations from another table).
    
- **No support for range and comparison queries**. Imagine we had a query that wanted to find all users born after a certain date. NoSQL databases cannot optimize this query and will have to scan all the rows to get the result, whereas relational databases would have no problems doing this optimally.
    
    **Limited range queries**: Scanning all data to filter (e.g., finding users born after 2000).
    

**Question: Does this mean that we can never have validation on the structure of data when we use non-relational databases?**

We can, but that will most likely have to be done in the application code. The application should validate the structure while writing or reading from the database and then handle errors accordingly. This is why these systems are also called as “**Schema on Read**”.

**Example**: Imagine a library without a catalog. When a user asks for a book, the librarian must check every shelf to find it. Validation occurs at the time of the query, not during storage.

**Transactional Support/BASE**

In general, document databases or non-relational databases are meant for single object reads and writes. They are built for blazing fast writes and for scaling horizontally. This means that generally they are not built to support “transactions” across objects or multiple operations. Supporting transactions consumes time and resources. Think about starting a logical transaction and then all the work you need to do for locking and to make sure all the operations within the transaction are complete and if not, all the rollback operations that need to be done, etc. Non-relational databases work best for use cases where transactional support is not needed across objects and operations.

Therefore, non-relational databases do not inherently support the ACID properties that relational databases do.

Instead of ACID, another term has been coined for non-relational databases called **BASE**. Base stands for **basically available, soft state and eventual consistency**. 

- Atomicity: Transactions are all-or-nothing.
- Consistency: Database remains valid after transactions.
- Isolation: Concurrent transactions don’t interfere.
- Durability: Data is saved permanently.

**Non-Relational Databases (BASE):**

- **Basically Available**: The system is always responsive.
- **Soft State**: Data may not be immediately consistent.
- **Eventual Consistency**: Consistency is achieved eventually, not instantly.

**Reason for BASE**: NoSQL databases prioritize speed and scalability over strict consistency, fitting scenarios where perfect data synchronization isn't critical (e.g., social media feeds).

**Question: So is it not possible to support transactions over multiple objects in a non-relational database?**

No, it is totally possible to have transaction support in a non-relational database. However, since they were not made with an intention to support transactions, they usually don't have “native” support for this. Therefore, typically the way to do that would be to run another layer of middleware on top of the non-relational database that does the transaction management for the application.

For example:

- **OMID** is a system that helps support transactions on HBase (which natively does not support multi-object transactions)
- Some non-relational databases, like **MongoDB**, have introduced support for multi-document transactions.

So now that we have seen relational and non-relational databases, let us list out some of the things we need to look out for while selecting the right type of DB for our system.

**Question: Is it true that “most” simple use cases can be implemented using relational databases?**

In general, it is mostly true that most simple use cases will work with relational DBs. However, the key thing to note here is that relational DBs might not be the best fit for your system and in some cases might be ***extremely suboptimal*** and lead to a degraded and poor performance.

If we wanted to understand this briefly, imagine we have a system that allows users to simply view and update their own names. This system needs to be able to support billions of users and a very high write/update traffic. The system also needs to scale horizontally to support more and more traffic.

Now, if we use a relational database, we are trading off high write performance in order to get transactional support. However, this system does not need transactional support (no multi object writes per operation) and therefore we would be giving away write performance for something we don't really need at all.

Secondly, this simplistic system does not *need* data to be stored in structured columns (since it's simply just the name) and read queries don't require complex joins (since you only read by user ID). Therefore, using relational databases don't give us any more advantage with read queries and unnecessarily might slow us down with unneeded strict schemas and system downtime when schema changes need to be propagated to the database.

**Selecting Between the Two**

So the question is, how do we select the right storage system for our system? To get a more thorough understanding of this, we need to answer a set of questions about the system in a way that tells us if we can benefit from the pros of each option and are okay to trade off the cons of that particular option. Here are some of them.

If your queries frequently involve joins or analyzing relationships between entities, go with a relational DB.

 If the data schema is dynamic and unpredictable, non-relational DBs provide the flexibility you need.

**What are the entities that we will be storing and retrieving from the database? Are these entities strongly connected to each other? In other words, do they have relationships with each other?**

In the above example, the only entity our system had was the user. Users have no relation to each other, and each user simply updates or views their own information.

Contrast this with the system that we discussed previously, the advertiser and ads data system, where we see a strong relationship among entities.

Therefore, if entities in a database have relationships with each other, a relational database would be a better fit for the system. Here, the advertiser system would benefit from a relational database whereas the user meta data would not really benefit from it.

**Is the structure of the data your system stores continuously evolving? Do you foresee more fields/attributes being added and removed all the time?**

We can imagine that the advertiser and ads data system is fairly structured. We might add attributes to the entities from time to time but it is not going to happen frequently. On the other hand, it's possible that the user metadata system keeps evolving in the data it stores. It may store names today but in the near future it's totally possible that we add more data like location, email, phone, birthdays, etc. Such systems that change continuously might not want to be bogged down by strict predefined schemas, and slow schema changes that cause downtime. They benefit better with non-relational databases.

**Even if there are relationships between entities, do we need strong transactional support while editing and reading these entities? Are operations done on several connected entities together?**

Now let's assume we have a social network where users can be friends with other users.

https://codahosted.io/docs/dD_gKH7E1I/blobs/bl-EHONoCpIUi/abe84a8efdf86a183037840a8703fa42afbe57a13ff047be68bd8a35a1ce1b069a4dc4b9a1699ef09bd49971d25eb0029a5eb91d20876c022019afeb39a294d3d2ff6b66736858bec0f8f0e76c3acc4c441937a8f16b206e10eac2e2aa49d9247cda4a62

Here, there are entities that have relationships with each other. It may be tempting to straight away choose a relational DB. However, we will probably ***never*** see a case where multiple of these entities and relationships are created as ***part of the same operation.*** Users usually create their own entities, and then friendship relations are created individually and separately at a later point in time.

To be more clear, we probably will not have cases where we want to create multiple users as well as friendship connections *in one go*. Furthermore, we won't have atomicity constraints where the entities and relationships all need to be created at once and if one relationship fails to be created, all the other entities need to be rolled back/deleted. Such systems benefit from non-relational databases because they don't need ACID support and can also benefit from much faster writes and ***much better scaling,*** which is what we would want from a social network.

On the other hand, the advertiser system may require that a campaign and a set of ads under it are all created ***in one operation.*** Failure to create the campaign entity should result **in no ads** getting created. Also, advertiser entities don't scale as fast as user entities in general, and so we are not bogged down by slightly slow writes. On the other hand, we do need the ACID support and therefore a relational database in general would do well here.

- **Entities and Relationships**: Users and friendships between users.
- **Operation Characteristics**:
    - Users create their profiles individually.
    - Friendships are established later and independently.
    - There is no need to batch-create multiple users and their friendship links in a single operation.
    - A failure to create a friendship link doesn’t require rolling back any user entities.

**In this case**:

- There’s no dependency on **strong transactional support** for operations spanning multiple entities.
- **Non-relational databases** excel here because:
    1. **Faster Writes**: The system avoids the overhead of ACID compliance.
    2. **Scalability**: Social networks often need to scale horizontally to accommodate billions of users and high write traffic.
    3. **Dynamic Schema**: User profiles may evolve (e.g., adding hobbies or custom statuses), which schema-less systems handle gracefully.

**What kind of read queries is the system going to support? Do we have “point” queries that don't require complex joins, or do we have queries requiring joins all the time?**

Point queries are queries that have simple constraints and don't require us to join data from multiple tables to get the results. For example, in the user metadata systems, all that the user can do is read their data given their ID and update their own data with the help of their ID. There is no real need for one user to query other users' information. Non-relational databases would work for such systems because they support blazing fast point queries.

On the other hand, the advertiser system does need to answer questions like “give us all the campaigns and ads of this advertiser”. Automatically, this would mean that we would have to join data from the campaigns and ads tables. In general, non-relational databases perform very poorly with joins. Remember, there is no structured set of columns and no concept of foreign keys, so the database wouldn’t be able to perform joins optimally. On the other hand, relational databases do really well with joins since the database knows the structure of the table well and can benefit from the indexes it has created for primary and foreign keys (We will talk about indexes in future chapters in more detail). Such cases benefit greatly from relational databases.

- **Entities and Relationships**: Advertisers, campaigns, and ads.
- **Operation Characteristics**:
    - A campaign creation might involve batch-creating multiple ads.
    - Failure to create a campaign should roll back all associated ads.
    - Advertisers and their campaigns have tightly connected data relationships.

**In this case:**

- **Transactional atomicity** is critical:
    - You don’t want partial data (e.g., campaigns created without ads) due to failures.
- **Relational databases** excel here because:
    1. **ACID Properties**: Ensure the atomicity, consistency, isolation, and durability of these operations.
    2. **Complex Queries**: Advertisers may want reports combining data from campaigns and ads, requiring optimized joins and foreign key relationships.

**Point Queries**

- These are simple queries where data is retrieved or updated by a unique identifier.
    - **Example**: "Get the user profile for user with ID X" or "Update the location for user with ID Y."
    - No joins or complex conditions are involved.

**Non-relational databases** are optimal for point queries:

1. **Blazing Fast Reads**: Keys are **indexed** for direct access.
2. **Schema-less Flexibility**: Each user’s data is self-contained, so schema changes won’t disrupt queries.

**Planning for the Future**

One pattern that we may see in the above Q&A is that we not only look at the current state of the system, but also plan a bit for the near future. We need to know briefly how the system is going to evolve over time, the query patterns that might change over time, the data that might change over time. Just looking at the current state of the data might give us a one-sided view, which might not be optimal.

**For example**, the user metadata system simply stores the names of users today. Knowing that, we may decide to go with a relational database. However, if we know that it's possible that more and more data is going to be added to this metadata store and that the fields are going to be added/removed very frequently, we might want to rethink the decision. Relational DBs will soon slow us down with slow schema changes and frequent application downtime, and therefore we might want to change our decision to using a non-relational database.

**Consider the Holistic Impact**

For the ease of understanding, we looked at each question individually and in isolation, but in practice, we need to look at all questions together holistically. For example, it's possible that answering one question might lead us to choose relational databases but in answering the next one, non-relational databases come out as the optimal choice. In such cases, we must:

1. Enlist all the pros and cons of each option with reference to the questions.
2. See if there are any non-negotiable requirements that come along the way. For example, if transactional support is absolutely needed, and we cannot give that away, even if the fields of the data keep changing very dynamically we might have to select relational databases and accept the disadvantage of frequent schema changes.
3. Finally, go with the option that maximizes how the system will benefit with the pros of that option and minimize the disadvantage we will face with the cons of the option. In all honesty, this is a world of trade-offs, and therefore we will very rarely have a system-database pair where we benefit from all the pros of the database and have no disadvantage from the cons of the database.